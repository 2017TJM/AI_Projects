{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.数据准备"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 加载训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from keras.datasets.cifar import load_batch\n",
    "\n",
    "## 加载数据集cifar10里面的训练集\n",
    "def load_train_dataset(dirPath='../resources/cifar-10-batches-py/'):\n",
    "    train_sample_quantity = 50000\n",
    "    image_width = 32\n",
    "    image_height = 32\n",
    "    channel_quantity = 3\n",
    "    train_X = np.zeros((train_sample_quantity, channel_quantity, image_width, image_height),\n",
    "                       dtype='uint8')\n",
    "    train_y = np.zeros((train_sample_quantity, ),\n",
    "                       dtype='uint8')\n",
    "    for i in range(1, 6):\n",
    "        fileName = 'data_batch_%d' %i\n",
    "        filePath = os.path.join(dirPath, fileName)\n",
    "        startIndex = (i - 1) * 10000\n",
    "        endIndex = i * 10000\n",
    "        train_X[startIndex:endIndex, :, :, :], train_y[startIndex:endIndex] = load_batch(filePath)\n",
    "    print('train_X矩阵转置前：', train_X.shape)\n",
    "    # 从官网上下载的数据集的4个维度为样本个数n、通道数c、宽度w、高度h\n",
    "    # Keras基于Tensorflow，数据的维度顺序要求：样本个数n、宽度w、高度h、通道数c，所以使用np.transpose完成矩阵转置\n",
    "    train_X = train_X.transpose(0, 2, 3, 1)\n",
    "    print('train_X矩阵转置后：', train_X.shape)\n",
    "    return train_X, train_y\n",
    "\n",
    "dirPath = '../resources/cifar-10-batches-py/'\n",
    "train_imageData, train_y = load_train_dataset() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 加载测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据集cifar10里面的测试集\n",
    "def load_test_dataset(dirPath='../resources/cifar-10-batches-py/'):\n",
    "    fileName = 'test_batch'\n",
    "    filePath = os.path.join(dirPath, fileName)\n",
    "    test_X, test_y = load_batch(filePath)\n",
    "    print('test_X矩阵转置前：', test_X.shape)\n",
    "    test_X = test_X.transpose(0, 2, 3, 1)\n",
    "    print('test_X矩阵转置后：', test_X.shape)\n",
    "    return test_X, test_y\n",
    "\n",
    "dirPath = '../resources/cifar-10-batches-py/'\n",
    "test_imageData, test_y = load_test_dataset() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 对类别做One-Hot编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对类别ID做One-Hot编码\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "class_quantity = 10\n",
    "train_Y = to_categorical(train_y, class_quantity)\n",
    "test_Y = to_categorical(test_y, class_quantity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 对图片像素的0-255值做归一化，并减去均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_imageData.astype('float32') / 255\n",
    "test_X = test_imageData.astype('float32') / 255\n",
    "pixel_mean = np.mean(train_X, axis=0)\n",
    "print('pixel_mean.shape:', pixel_mean.shape)\n",
    "train_X = train_X - pixel_mean\n",
    "test_X = test_X - pixel_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.使用load_model方法加载模型文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "model_filePath = '../resources/saved_models/cifar10_ResNet56v2_model.162.h5'\n",
    "model = load_model(model_filePath)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 计算训练集的准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score trained model on train dataset\n",
    "scores = model.evaluate(train_X, train_Y, verbose=1, batch_size=1000)\n",
    "print('Test loss:%.6f' %scores[0])\n",
    "print('Test accuracy:%.6f' %scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 计算测试集的准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score trained model on test dataset\n",
    "scores = model.evaluate(test_X, test_Y, verbose=1, batch_size=1000)\n",
    "print('Test loss:%.6f' %scores[0])\n",
    "print('Test accuracy:%.6f' %scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.模型测试结果可视化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 随机选取100张图片并展示测试结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.rcParams['font.sans-serif'] = ['SimHei']\n",
    "import random\n",
    "\n",
    "def draw_image(position, image, title, isTrue):\n",
    "    plt.subplot(*position)\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    if not isTrue:\n",
    "        plt.title(title, color='red')\n",
    "    else:\n",
    "        plt.title(title)\n",
    "        \n",
    "def batch_draw_images(model, batch_size, test_imageData, test_X, test_y, id2name_dict):\n",
    "    index_list = list(range(len(test_imageData)))\n",
    "    selected_index_list = random.sample(index_list, batch_size)\n",
    "    true_imageData = test_imageData[selected_index_list]\n",
    "    true_X = test_X[selected_index_list]\n",
    "    true_y = np.array(test_y)[selected_index_list]\n",
    "    predict_Y = model.predict(true_X)\n",
    "    predict_y = np.argmax(predict_Y, axis=1)\n",
    "    row_number = math.ceil(batch_size ** 0.5)\n",
    "    column_number = row_number\n",
    "    plt.figure(figsize=(row_number+8, column_number+8))\n",
    "    for i in range(row_number):\n",
    "        for j in range(column_number):\n",
    "            index = i * column_number + j\n",
    "            if index < batch_size:\n",
    "                position = (row_number, column_number, index+1)\n",
    "                image = true_imageData[index]\n",
    "                actual_classId = true_y[index]\n",
    "                predict_classId = predict_y[index]\n",
    "                isTrue = actual_classId==predict_classId\n",
    "                actual_className = id2name_dict[actual_classId]\n",
    "                predict_className = id2name_dict[predict_classId]\n",
    "                title = 'actual:%s\\npredict:%s' %(actual_className, predict_className)\n",
    "                draw_image(position, image, title, isTrue)\n",
    "\n",
    "batch_size = 100    \n",
    "className_list = ['飞机', '汽车', '鸟', '猫', '鹿', '狗', '青蛙', '马', '船', '卡车']\n",
    "id2name_dict = {a:b for a, b in enumerate(className_list)}\n",
    "batch_draw_images(model, batch_size, test_imageData, test_X, test_y, id2name_dict)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 随机选取100张图片的同时，要求10个类别，每个类别取10张"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_selectedIndexList(test_y, batch_size):\n",
    "    assert batch_size % 10 == 0, 'batch_size must be times by 10, or you change function get_selectedIndexList'\n",
    "    column_number = int(batch_size / 10)\n",
    "    classId_ndarray = np.unique(test_y)\n",
    "    selected_index_list = []\n",
    "    for i, classId in enumerate(classId_ndarray):\n",
    "        index_ndarray = np.where(test_y==classId)[0]\n",
    "        selected_index_ndarray = np.random.choice(index_ndarray, column_number)\n",
    "        selected_index_list.extend(selected_index_ndarray.tolist())\n",
    "    return selected_index_list    \n",
    "        \n",
    "def batch_draw_images_2(model, selected_index_list, test_imageData, test_X, test_y, id2name_dict):\n",
    "    true_imageData = test_imageData[selected_index_list]\n",
    "    true_X = test_X[selected_index_list]\n",
    "    true_y = np.array(test_y)[selected_index_list]\n",
    "    predict_Y = model.predict(true_X)\n",
    "    predict_y = np.argmax(predict_Y, axis=1)\n",
    "    row_number = math.ceil(batch_size ** 0.5)\n",
    "    column_number = row_number\n",
    "    plt.figure(figsize=(row_number+8, column_number+8))\n",
    "    for i in range(row_number):\n",
    "        for j in range(column_number):\n",
    "            index = i * column_number + j\n",
    "            if index < batch_size:\n",
    "                position = (row_number, column_number, index+1)\n",
    "                image = true_imageData[index]\n",
    "                actual_classId = true_y[index]\n",
    "                predict_classId = predict_y[index]\n",
    "                isTrue = actual_classId==predict_classId\n",
    "                actual_className = id2name_dict[actual_classId]\n",
    "                predict_className = id2name_dict[predict_classId]\n",
    "                title = 'actual:%s\\npredict:%s' %(actual_className, predict_className)\n",
    "                draw_image(position, image, title, isTrue)\n",
    "\n",
    "batch_size = 100     \n",
    "className_list = ['飞机', '汽车', '鸟', '猫', '鹿', '狗', '青蛙', '马', '船', '卡车']\n",
    "id2name_dict = {a:b for a, b in enumerate(className_list)}\n",
    "selected_index_list = get_selectedIndexList(test_y, batch_size)\n",
    "batch_draw_images_2(model, selected_index_list, test_imageData, test_X, test_y, id2name_dict)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.Keras中权重文件的读写"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 使用save_weights方法保存权重文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_h5FilePath = '../resources/saved_models/resnet56v2_weights.h5'\n",
    "model.save_weights(weights_h5FilePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 使用load_weights方法加载权重文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "from keras.layers import AveragePooling2D, Input, Flatten\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Model\n",
    "\n",
    "def resnet_layer(inputs,\n",
    "                 num_filters=16,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 activation='relu',\n",
    "                 batch_normalization=True,\n",
    "                 conv_first=True):\n",
    "    conv = Conv2D(num_filters,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=strides,\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal',\n",
    "                  kernel_regularizer=l2(1e-4))\n",
    "    x = inputs\n",
    "    if conv_first:\n",
    "        x = conv(x)\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "    else:\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "        x = conv(x)\n",
    "    return x\n",
    "\n",
    "def resnet_v2(input_shape, depth, num_classes=10):\n",
    "    if (depth - 2) % 9 != 0:\n",
    "        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n",
    "    # Start model definition.\n",
    "    num_filters_in = 16\n",
    "    num_res_blocks = int((depth - 2) / 9)\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n",
    "    x = resnet_layer(inputs=inputs,\n",
    "                     num_filters=num_filters_in,\n",
    "                     conv_first=True)\n",
    "\n",
    "    # Instantiate the stack of residual units\n",
    "    for stage in range(3):\n",
    "        for res_block in range(num_res_blocks):\n",
    "            activation = 'relu'\n",
    "            batch_normalization = True\n",
    "            strides = 1\n",
    "            if stage == 0:\n",
    "                num_filters_out = num_filters_in * 4\n",
    "                if res_block == 0:  # first layer and first stage\n",
    "                    activation = None\n",
    "                    batch_normalization = False\n",
    "            else:\n",
    "                num_filters_out = num_filters_in * 2\n",
    "                if res_block == 0:  # first layer but not first stage\n",
    "                    strides = 2    # downsample\n",
    "\n",
    "            # bottleneck residual unit\n",
    "            y = resnet_layer(inputs=x,\n",
    "                             num_filters=num_filters_in,\n",
    "                             kernel_size=1,\n",
    "                             strides=strides,\n",
    "                             activation=activation,\n",
    "                             batch_normalization=batch_normalization,\n",
    "                             conv_first=False)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters_in,\n",
    "                             conv_first=False)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters_out,\n",
    "                             kernel_size=1,\n",
    "                             conv_first=False)\n",
    "            if res_block == 0:\n",
    "                # linear projection residual shortcut connection to match\n",
    "                # changed dims\n",
    "                x = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters_out,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = keras.layers.add([x, y])\n",
    "        num_filters_in = num_filters_out\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v2 has BN-ReLU before Pooling\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    y = Flatten()(x)\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (32, 32, 3)\n",
    "depth = 56\n",
    "model = resnet_v2(input_shape, depth)\n",
    "weights_h5FilePath = '../resources/saved_models/resnet56v2_weights.h5'\n",
    "model.load_weights(weights_h5FilePath)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
